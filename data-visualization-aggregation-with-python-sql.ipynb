{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019198,
     "end_time": "2021-01-20T03:37:06.886989",
     "exception": false,
     "start_time": "2021-01-20T03:37:06.867791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATA VISUALIZATION & DATA AGGREGATION WITH PYTHON & SQL\n",
    "[Muhammad Rifki](https://www.linkedin.com/in/muhammadrifki/) - January 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01492,
     "end_time": "2021-01-20T03:37:06.918554",
     "exception": false,
     "start_time": "2021-01-20T03:37:06.903634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The objective of this notebook is merely an exercise to showcase some required skills for a Business Intelligence like SQL query and Python language. Thus, I do some simple data visualization & aggregation of e-commerce in Brazil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:06.959050Z",
     "iopub.status.busy": "2021-01-20T03:37:06.958185Z",
     "iopub.status.idle": "2021-01-20T03:37:08.230582Z",
     "shell.execute_reply": "2021-01-20T03:37:08.229005Z"
    },
    "papermill": {
     "duration": 1.29604,
     "end_time": "2021-01-20T03:37:08.230718",
     "exception": false,
     "start_time": "2021-01-20T03:37:06.934678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import plotly.express as px\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Local server SQL database\n",
    "import sqlite3 as sq\n",
    "\n",
    "# Setting of Large numbers format\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# Set data frame display max 10 rows\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "# Warning is suppressed\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:08.268913Z",
     "iopub.status.busy": "2021-01-20T03:37:08.268052Z",
     "iopub.status.idle": "2021-01-20T03:37:08.271812Z",
     "shell.execute_reply": "2021-01-20T03:37:08.271128Z"
    },
    "papermill": {
     "duration": 0.024651,
     "end_time": "2021-01-20T03:37:08.271936",
     "exception": false,
     "start_time": "2021-01-20T03:37:08.247285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set-up a connection to a newly named project1.db\n",
    "con = sq.connect('project1.db')\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:08.311429Z",
     "iopub.status.busy": "2021-01-20T03:37:08.310686Z",
     "iopub.status.idle": "2021-01-20T03:37:22.069039Z",
     "shell.execute_reply": "2021-01-20T03:37:22.067925Z"
    },
    "papermill": {
     "duration": 13.781192,
     "end_time": "2021-01-20T03:37:22.069219",
     "exception": false,
     "start_time": "2021-01-20T03:37:08.288027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the count of customers_dataset table\n",
    "cur.execute(''' SELECT count(name) FROM sqlite_master WHERE type='table' AND name='../input/brazilian-ecommerce/olist_customers_dataset.csv' OR name='customers_dataset' ''')\n",
    "\n",
    "# If the count is 1, then customers_dataset table already exists\n",
    "if cur.fetchone()[0]==1 : {\n",
    "\tprint('Table already created.')\n",
    "}\n",
    "else: # Read all files from csv to db format\n",
    "    path = '../input/brazilian-ecommerce'\n",
    "    all_files = glob.glob(path + \"/*.csv\")\n",
    "    for file in all_files: # For all files in our directory\n",
    "        df = pd.read_csv(file, index_col=0) # Read each CSV file\n",
    "        df.to_sql(file, con) # Create the read file as a table in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:22.116743Z",
     "iopub.status.busy": "2021-01-20T03:37:22.115599Z",
     "iopub.status.idle": "2021-01-20T03:37:22.251245Z",
     "shell.execute_reply": "2021-01-20T03:37:22.250561Z"
    },
    "papermill": {
     "duration": 0.162038,
     "end_time": "2021-01-20T03:37:22.251376",
     "exception": false,
     "start_time": "2021-01-20T03:37:22.089338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'ALTER TABLE \"../input/brazilian-ecommerce/olist_customers_dataset.csv\" RENAME TO \"customers_dataset\"': no such table: ../input/brazilian-ecommerce/olist_customers_dataset.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1680\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: ../input/brazilian-ecommerce/olist_customers_dataset.csv",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b74050c0e1e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# The function read_sql takes a query string and a database connection, and performs the query.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mrename_tables1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrename_tables_query1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mrename_tables2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrename_tables_query2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mrename_tables3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrename_tables_query3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandas_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSQLiteDatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    484\u001b[0m             \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Execution failed on sql '{args[0]}': {exc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'ALTER TABLE \"../input/brazilian-ecommerce/olist_customers_dataset.csv\" RENAME TO \"customers_dataset\"': no such table: ../input/brazilian-ecommerce/olist_customers_dataset.csv"
     ]
    }
   ],
   "source": [
    "# Get the count of customers_dataset table\n",
    "cur.execute(''' SELECT count(name) FROM sqlite_master WHERE type='table' AND name='customers_dataset' ''')\n",
    "\n",
    "# If the count is 1, then customers_dataset table already renamed\n",
    "if cur.fetchone()[0]==1:\n",
    "\tprint('Table already renamed.')\n",
    "\n",
    "else:\n",
    "    # Rename all tables\n",
    "    rename_tables_query1 = 'ALTER TABLE \"../input/brazilian-ecommerce/olist_customers_dataset.csv\" RENAME TO \"customers_dataset\"'\n",
    "    rename_tables_query2 = 'ALTER TABLE \"../input/brazilian-ecommerce/olist_geolocation_dataset.csv\" RENAME TO \"geolocation_dataset\"'\n",
    "    rename_tables_query3 = 'ALTER TABLE \"../input/brazilian-ecommerce/olist_orders_dataset.csv\" RENAME TO \"orders_dataset\"'\n",
    "    rename_tables_query4 = 'ALTER TABLE \"../input/brazilian-ecommerce/olist_order_items_dataset.csv\" RENAME TO \"order_items_dataset\"'\n",
    "    rename_tables_query5 = 'ALTER TABLE \"../input/brazilian-ecommerce/olist_order_payments_dataset.csv\" RENAME TO \"order_payments_dataset\"'\n",
    "    rename_tables_query6 = 'ALTER TABLE \"../input/brazilian-ecommerce/olist_order_reviews_dataset.csv\" RENAME TO \"order_reviews_dataset\"'\n",
    "    rename_tables_query7 = 'ALTER TABLE \"../input/brazilian-ecommerce/olist_products_dataset.csv\" RENAME TO \"products_dataset\"'\n",
    "    rename_tables_query8 = 'ALTER TABLE \"../input/brazilian-ecommerce/olist_sellers_dataset.csv\" RENAME TO \"sellers_dataset\"'\n",
    "    rename_tables_query9 = 'ALTER TABLE \"../input/brazilian-ecommerce/product_category_name_translation.csv\" RENAME TO \"product_category_name_translation\"'\n",
    "\n",
    "    # The function read_sql takes a query string and a database connection, and performs the query.\n",
    "    rename_tables1 = pd.read_sql(rename_tables_query1, con)\n",
    "    rename_tables2 = pd.read_sql(rename_tables_query2, con)\n",
    "    rename_tables3 = pd.read_sql(rename_tables_query3, con)\n",
    "    rename_tables4 = pd.read_sql(rename_tables_query4, con)\n",
    "    rename_tables5 = pd.read_sql(rename_tables_query5, con)\n",
    "    rename_tables6 = pd.read_sql(rename_tables_query6, con)\n",
    "    rename_tables7 = pd.read_sql(rename_tables_query7, con)\n",
    "    rename_tables8 = pd.read_sql(rename_tables_query8, con)\n",
    "    rename_tables9 = pd.read_sql(rename_tables_query9, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:22.289370Z",
     "iopub.status.busy": "2021-01-20T03:37:22.288201Z",
     "iopub.status.idle": "2021-01-20T03:37:22.292821Z",
     "shell.execute_reply": "2021-01-20T03:37:22.293480Z"
    },
    "papermill": {
     "duration": 0.026449,
     "end_time": "2021-01-20T03:37:22.293632",
     "exception": false,
     "start_time": "2021-01-20T03:37:22.267183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read all table names\n",
    "table_list = [a for a in cur.execute(\"SELECT name FROM sqlite_master WHERE type = 'table'\")]\n",
    "\n",
    "# Table list\n",
    "print(table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:22.334836Z",
     "iopub.status.busy": "2021-01-20T03:37:22.334139Z",
     "iopub.status.idle": "2021-01-20T03:37:22.446166Z",
     "shell.execute_reply": "2021-01-20T03:37:22.445600Z"
    },
    "papermill": {
     "duration": 0.135684,
     "end_time": "2021-01-20T03:37:22.446302",
     "exception": false,
     "start_time": "2021-01-20T03:37:22.310618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a SQL query of Total Orders and Total Sales\n",
    "q1 = (\n",
    "      'SELECT count(a.order_id) AS Total_Orders, '\n",
    "      '       sum(b.price + b.freight_value) AS Total_Sales '\n",
    "      'FROM orders_dataset AS a '\n",
    "      'INNER JOIN order_items_dataset AS b '\n",
    "      'ON a.order_id = b.order_id '\n",
    "      )\n",
    "\n",
    "# Convert the SQL query to Pandas data Frame\n",
    "r1 = pd.read_sql(q1, con)\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:22.485777Z",
     "iopub.status.busy": "2021-01-20T03:37:22.485110Z",
     "iopub.status.idle": "2021-01-20T03:37:22.662485Z",
     "shell.execute_reply": "2021-01-20T03:37:22.661835Z"
    },
    "papermill": {
     "duration": 0.199422,
     "end_time": "2021-01-20T03:37:22.662638",
     "exception": false,
     "start_time": "2021-01-20T03:37:22.463216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a SQL query of Orders by Time\n",
    "q2 = (\n",
    "      'SELECT strftime(\"%Y-%m\", order_approved_at) AS date, '\n",
    "      '       COUNT(order_id) AS order_qty '\n",
    "      'FROM orders_dataset '\n",
    "      'GROUP BY date '\n",
    "      'ORDER BY date '\n",
    "      )\n",
    "\n",
    "# Convert the SQL query to Pandas data Frame\n",
    "r2 = pd.read_sql(q2, con)\n",
    "r2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:22.727094Z",
     "iopub.status.busy": "2021-01-20T03:37:22.726094Z",
     "iopub.status.idle": "2021-01-20T03:37:24.124180Z",
     "shell.execute_reply": "2021-01-20T03:37:24.123570Z"
    },
    "papermill": {
     "duration": 1.432228,
     "end_time": "2021-01-20T03:37:24.124297",
     "exception": false,
     "start_time": "2021-01-20T03:37:22.692069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting orders by time data \n",
    "fig1 = px.bar(r2, x=\"date\", y=\"order_qty\", orientation='v', title='Orders by Date in Brazilian E-Commerce (2016-2018)')\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:24.168032Z",
     "iopub.status.busy": "2021-01-20T03:37:24.166878Z",
     "iopub.status.idle": "2021-01-20T03:37:24.736647Z",
     "shell.execute_reply": "2021-01-20T03:37:24.736067Z"
    },
    "papermill": {
     "duration": 0.593844,
     "end_time": "2021-01-20T03:37:24.736759",
     "exception": false,
     "start_time": "2021-01-20T03:37:24.142915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a SQL query of Sales by Time\n",
    "q3 = (\n",
    "      'SELECT strftime(\"%Y-%m\", a.order_approved_at) AS date, '\n",
    "      '       SUM(b.price) AS sales '\n",
    "      'FROM orders_dataset AS a '\n",
    "      'INNER JOIN order_items_dataset AS b '\n",
    "      'ON a.order_id = b.order_id '\n",
    "      'GROUP BY date '\n",
    "      'ORDER BY date '\n",
    "      )\n",
    "\n",
    "# Convert the SQL query to Pandas data Frame\n",
    "r3 = pd.read_sql(q3, con)\n",
    "r3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:24.782162Z",
     "iopub.status.busy": "2021-01-20T03:37:24.781279Z",
     "iopub.status.idle": "2021-01-20T03:37:24.872279Z",
     "shell.execute_reply": "2021-01-20T03:37:24.872767Z"
    },
    "papermill": {
     "duration": 0.116772,
     "end_time": "2021-01-20T03:37:24.872919",
     "exception": false,
     "start_time": "2021-01-20T03:37:24.756147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting sales by time data \n",
    "fig2 = px.line(r3, x=\"date\", y=\"sales\", title='Sales by Time in Brazilian E-Commerce (2016-2018)')\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:24.916796Z",
     "iopub.status.busy": "2021-01-20T03:37:24.916172Z",
     "iopub.status.idle": "2021-01-20T03:37:24.965847Z",
     "shell.execute_reply": "2021-01-20T03:37:24.965269Z"
    },
    "papermill": {
     "duration": 0.072531,
     "end_time": "2021-01-20T03:37:24.965982",
     "exception": false,
     "start_time": "2021-01-20T03:37:24.893451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a SQL query of Selling Product Categories Quantity\n",
    "q4 = (\n",
    "      'SELECT a.product_category_name_english AS product, '\n",
    "      '       COUNT(b.product_category_name) AS qty '\n",
    "      'FROM product_category_name_translation AS a '\n",
    "      'INNER JOIN products_dataset AS b '\n",
    "      'ON a.product_category_name = b.product_category_name '\n",
    "      'GROUP BY product '\n",
    "      'ORDER BY qty DESC '\n",
    "      )\n",
    "\n",
    "# Convert the SQL query to Pandas data Frame\n",
    "r4 = pd.read_sql(q4, con)\n",
    "r4_top = r4.head(5)\n",
    "r4_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:25.066726Z",
     "iopub.status.busy": "2021-01-20T03:37:25.039116Z",
     "iopub.status.idle": "2021-01-20T03:37:25.083714Z",
     "shell.execute_reply": "2021-01-20T03:37:25.084269Z"
    },
    "papermill": {
     "duration": 0.096538,
     "end_time": "2021-01-20T03:37:25.084418",
     "exception": false,
     "start_time": "2021-01-20T03:37:24.987880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting selling product categories quantity data\n",
    "fig3 = px.bar(r4_top, x=\"qty\", y=\"product\", orientation='h', barmode=\"group\", title='Top 5 Selling Product Categories in Brazilian E-Commerce (2016-2018)')\n",
    "fig3.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:25.135579Z",
     "iopub.status.busy": "2021-01-20T03:37:25.134786Z",
     "iopub.status.idle": "2021-01-20T03:37:25.347253Z",
     "shell.execute_reply": "2021-01-20T03:37:25.346657Z"
    },
    "papermill": {
     "duration": 0.241126,
     "end_time": "2021-01-20T03:37:25.347383",
     "exception": false,
     "start_time": "2021-01-20T03:37:25.106257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a SQL query of Sellers by City\n",
    "q5 = (\n",
    "      'WITH temp_sellers AS '\n",
    "      '( '\n",
    "      '      SELECT a.seller_city AS seller_city, '\n",
    "      '      COUNT(b.order_id) AS sales_qty, '\n",
    "      '      COUNT(b.order_id) * 100.0 / SUM(COUNT(b.order_id)) OVER () AS temp_sales_percentage '\n",
    "      '      FROM sellers_dataset AS a '\n",
    "      '      INNER JOIN order_items_dataset AS b '\n",
    "      '      ON a.seller_id = b.seller_id '\n",
    "      '      GROUP BY seller_city '\n",
    "      '      ORDER BY sales_qty DESC '\n",
    "      ') '\n",
    "      'SELECT seller_city, '\n",
    "      '       sales_qty, '\n",
    "      '       printf(\"%.2f\", temp_sales_percentage) AS sales_percentage '\n",
    "      'FROM temp_sellers '\n",
    "      )\n",
    "\n",
    "# Convert the SQL query to Pandas data Frame\n",
    "r5 = pd.read_sql(q5, con)\n",
    "r5_top = r5.head(5)\n",
    "r5_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:25.405407Z",
     "iopub.status.busy": "2021-01-20T03:37:25.404645Z",
     "iopub.status.idle": "2021-01-20T03:37:25.503051Z",
     "shell.execute_reply": "2021-01-20T03:37:25.502429Z"
    },
    "papermill": {
     "duration": 0.133411,
     "end_time": "2021-01-20T03:37:25.503170",
     "exception": false,
     "start_time": "2021-01-20T03:37:25.369759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting selling sellers by city data\n",
    "fig4 = px.bar(r5_top, x=\"sales_qty\", y=\"seller_city\", orientation='h', hover_data=['sales_percentage'], color='sales_percentage', title='Top 5 Sellers by City in Brazilian E-Commerce (2016-2018)')\n",
    "fig4.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:25.557668Z",
     "iopub.status.busy": "2021-01-20T03:37:25.556930Z",
     "iopub.status.idle": "2021-01-20T03:37:26.301728Z",
     "shell.execute_reply": "2021-01-20T03:37:26.301048Z"
    },
    "papermill": {
     "duration": 0.774517,
     "end_time": "2021-01-20T03:37:26.301841",
     "exception": false,
     "start_time": "2021-01-20T03:37:25.527324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a SQL query of Customers by City\n",
    "q6 = (\n",
    "      'WITH temp_customer AS '\n",
    "      '( '\n",
    "      '      SELECT a.customer_city AS customer_city, '\n",
    "      '      COUNT(b.order_id) AS order_qty, '\n",
    "      '      COUNT(b.order_id) * 100.0 / SUM(COUNT(b.order_id)) OVER () AS temp_order_percentage '\n",
    "      '      FROM customers_dataset AS a '\n",
    "      '      INNER JOIN orders_dataset AS b '\n",
    "      '      ON a.customer_id = b.customer_id '\n",
    "      '      GROUP BY customer_city '\n",
    "      '      ORDER BY order_qty DESC '\n",
    "      ') '\n",
    "      'SELECT customer_city, '\n",
    "      '       order_qty, '\n",
    "      '       printf(\"%.2f\", temp_order_percentage) AS order_percentage '\n",
    "      'FROM temp_customer '\n",
    "      )\n",
    "\n",
    "# Convert the SQL query to Pandas data Frame\n",
    "r6 = pd.read_sql(q6, con)\n",
    "r6_top = r6.head(5)\n",
    "r6_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:26.394393Z",
     "iopub.status.busy": "2021-01-20T03:37:26.363745Z",
     "iopub.status.idle": "2021-01-20T03:37:26.447110Z",
     "shell.execute_reply": "2021-01-20T03:37:26.446406Z"
    },
    "papermill": {
     "duration": 0.121025,
     "end_time": "2021-01-20T03:37:26.447290",
     "exception": false,
     "start_time": "2021-01-20T03:37:26.326265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting selling customer by city data\n",
    "fig5 = px.bar(r6_top, x=\"order_qty\", y=\"customer_city\", orientation='h', hover_data=['order_percentage'], color='order_percentage', title='Top 5 Customers by City in Brazilian E-Commerce (2016-2018)')\n",
    "fig5.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "fig5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:26.504474Z",
     "iopub.status.busy": "2021-01-20T03:37:26.503370Z",
     "iopub.status.idle": "2021-01-20T03:37:26.559996Z",
     "shell.execute_reply": "2021-01-20T03:37:26.559000Z"
    },
    "papermill": {
     "duration": 0.087722,
     "end_time": "2021-01-20T03:37:26.560154",
     "exception": false,
     "start_time": "2021-01-20T03:37:26.472432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a SQL query of Average, Max, and Min Products\n",
    "q7 = (\n",
    "      'SELECT AVG(price) AS Average_Price, '\n",
    "      '       MAX(price) AS Max_Price, '\n",
    "      '       MIN(price) AS Min_Price '\n",
    "      'FROM order_items_dataset '\n",
    "      )\n",
    "\n",
    "# Convert the SQL query to Pandas data Frame\n",
    "r7 = pd.read_sql(q7, con)\n",
    "r7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:26.618882Z",
     "iopub.status.busy": "2021-01-20T03:37:26.617741Z",
     "iopub.status.idle": "2021-01-20T03:37:26.681346Z",
     "shell.execute_reply": "2021-01-20T03:37:26.680745Z"
    },
    "papermill": {
     "duration": 0.095348,
     "end_time": "2021-01-20T03:37:26.681465",
     "exception": false,
     "start_time": "2021-01-20T03:37:26.586117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "q8 = (\n",
    "      'WITH average_time AS '\n",
    "      '( '\n",
    "      '     SELECT julianday(order_estimated_delivery_date) - julianday(order_delivered_customer_date) AS delivery_time '\n",
    "      '     FROM orders_dataset '\n",
    "      '     WHERE order_status = \"delivered\" '\n",
    "      ') '\n",
    "      'SELECT AVG(delivery_time) AS \"Average_Delivery_Time_Interval_(Estimated_vs_Actual)\" '\n",
    "      'FROM average_time '\n",
    "      )\n",
    "\n",
    "# Convert the SQL query to Pandas data Frame\n",
    "r8 = pd.read_sql(q8, con)\n",
    "r8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:26.742019Z",
     "iopub.status.busy": "2021-01-20T03:37:26.740851Z",
     "iopub.status.idle": "2021-01-20T03:37:26.927124Z",
     "shell.execute_reply": "2021-01-20T03:37:26.926426Z"
    },
    "papermill": {
     "duration": 0.219688,
     "end_time": "2021-01-20T03:37:26.927239",
     "exception": false,
     "start_time": "2021-01-20T03:37:26.707551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a SQL query of Delivery Interval (Estimated vs Actual) per Month\n",
    "q9 = (\n",
    "      'WITH average_time AS '\n",
    "      '( '\n",
    "      '     SELECT strftime(\"%Y-%m\", order_delivered_customer_date) AS date, '\n",
    "      '            julianday(order_estimated_delivery_date) - julianday(order_delivered_customer_date) AS delivery_time, '\n",
    "      '            COUNT(order_id) AS qty'\n",
    "      '     FROM orders_dataset '\n",
    "      '     WHERE order_status = \"delivered\" '\n",
    "      '     GROUP BY date '\n",
    "      '     ORDER BY date '\n",
    "      ') '\n",
    "      'SELECT date AS Date, delivery_time AS Day, qty AS Qty '\n",
    "      'FROM average_time '\n",
    "      )\n",
    "\n",
    "# Convert the SQL query to Pandas data Frame\n",
    "r9 = pd.read_sql(q9, con)\n",
    "r9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:26.993356Z",
     "iopub.status.busy": "2021-01-20T03:37:26.992477Z",
     "iopub.status.idle": "2021-01-20T03:37:27.082555Z",
     "shell.execute_reply": "2021-01-20T03:37:27.081409Z"
    },
    "papermill": {
     "duration": 0.127661,
     "end_time": "2021-01-20T03:37:27.082691",
     "exception": false,
     "start_time": "2021-01-20T03:37:26.955030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting Delivery Interval (Estimated vs Actual) per Month data \n",
    "fig6 = px.bar(r9, x=\"Date\", y=\"Day\", orientation='v', hover_data=['Qty'], color='Qty', title='Delivery Interval (Estimated vs Actual) per Month in<br>Brazilian E-Commerce (2016-2018)')\n",
    "fig6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T03:37:27.144557Z",
     "iopub.status.busy": "2021-01-20T03:37:27.143391Z",
     "iopub.status.idle": "2021-01-20T03:37:27.146993Z",
     "shell.execute_reply": "2021-01-20T03:37:27.146272Z"
    },
    "papermill": {
     "duration": 0.036858,
     "end_time": "2021-01-20T03:37:27.147129",
     "exception": false,
     "start_time": "2021-01-20T03:37:27.110271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Close connection to Database\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 25.68465,
   "end_time": "2021-01-20T03:37:27.287265",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-20T03:37:01.602615",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
